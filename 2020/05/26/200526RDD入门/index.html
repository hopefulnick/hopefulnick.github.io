<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon32.jpg?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon16.jpg?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="RDD," />










<meta name="description" content="1 概览Spark具有两大抽象： RDD和共享变量。">
<meta name="keywords" content="RDD">
<meta property="og:type" content="article">
<meta property="og:title" content="RDD入门">
<meta property="og:url" content="https://hopefulnick.github.io/2020/05/26/200526RDD入门/index.html">
<meta property="og:site_name" content="Hopeful Nick">
<meta property="og:description" content="1 概览Spark具有两大抽象： RDD和共享变量。">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://hopefulnick.github.io/2020/05/26/200526RDD入门/image-20200530113809031.png">
<meta property="og:image" content="https://hopefulnick.github.io/2020/05/26/200526RDD入门/image-20200602175340948.png">
<meta property="og:image" content="https://hopefulnick.github.io/2020/05/26/200526RDD入门/image-20200602204104723.png">
<meta property="og:image" content="https://hopefulnick.github.io/2020/05/26/200526RDD入门/image-20200607152307918.png">
<meta property="og:updated_time" content="2020-11-12T03:40:11.095Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="RDD入门">
<meta name="twitter:description" content="1 概览Spark具有两大抽象： RDD和共享变量。">
<meta name="twitter:image" content="https://hopefulnick.github.io/2020/05/26/200526RDD入门/image-20200530113809031.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://hopefulnick.github.io/2020/05/26/200526RDD入门/"/>





  <title>RDD入门 | Hopeful Nick</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hopeful Nick</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://hopefulnick.github.io/2020/05/26/200526RDD入门/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Hopeful Nick">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hopeful Nick">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">RDD入门</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-05-26T11:00:47+08:00">
                2020-05-26
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Spark/" itemprop="url" rel="index">
                    <span itemprop="name">Spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/05/26/200526RDD入门/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2020/05/26/200526RDD入门/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="1-概览"><a href="#1-概览" class="headerlink" title="1 概览"></a>1 概览</h2><p>Spark具有两大抽象： RDD和共享变量。</p>
<a id="more"></a>
<p>RDD是节点间分区并行操作的元素集合。可以通过Hadoop支持的文件系统中的文件或者已有的RDD转换得到。可以持久化，也可以容灾恢复。</p>
<p>共享变量是并行任务间共享的数据。分为广播变量和累加器。</p>
<h2 id="2-连接Spark"><a href="#2-连接Spark" class="headerlink" title="2 连接Spark"></a>2 连接Spark</h2><p>Spark 2.4.5默认使用Scala 2.12,可以自行编译其他版本。</p>
<p>Maven依赖：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">// Spark</span><br><span class="line">groupId = org.apache.spark</span><br><span class="line">artifactId = spark-core_2.12</span><br><span class="line">version = 2.4.5</span><br><span class="line"></span><br><span class="line">// 访问HDFS集群，&lt;your-hdfs-version&gt;修改为对应版本</span><br><span class="line">groupId = org.apache.hadoop</span><br><span class="line">artifactId = hadoop-client</span><br><span class="line">version = &lt;your-hdfs-version&gt;</span><br></pre></td></tr></table></figure>
<p>导入类：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkContext</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// &lt; 1.3.0, 开启隐式转换</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkContext</span>._</span><br></pre></td></tr></table></figure>
<h2 id="3-初始化Spark"><a href="#3-初始化Spark" class="headerlink" title="3 初始化Spark"></a>3 初始化Spark</h2><h3 id="1-应用程序"><a href="#1-应用程序" class="headerlink" title="(1) 应用程序"></a>(1) 应用程序</h3><p>SparkConf用于提供应用信息，每个JVM只能有一个。</p>
<p>SparkContext用于访问集群</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// appName 集群UI显示的应用名称</span></span><br><span class="line"><span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(appName).setMaster(master)</span><br><span class="line"><span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br></pre></td></tr></table></figure>
<p>master:</p>
<p><img src="/2020/05/26/200526RDD入门/image-20200530113809031.png" alt="image-20200530113809031"></p>
<p>如果不想硬编码master，可以使用spark-submit</p>
<h3 id="2-交互命令行"><a href="#2-交互命令行" class="headerlink" title="(2) 交互命令行"></a>(2) 交互命令行</h3><p>spark-shell自动创建SparkContext，忽略用户创建的。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// --master 指定连接的主节点</span><br><span class="line">// --jars 添加逗号分隔的JAR</span><br><span class="line">// --packages 添加Maven依赖</span><br><span class="line">// --repositories 添加依赖仓库，如Sonatype</span><br><span class="line"><span class="meta">$</span> ./bin/spark-shell --master local[4] --jars code.jar</span><br><span class="line"><span class="meta">$</span> ./bin/spark-shell --master local[4] --packages "org.example:example:0.1"</span><br></pre></td></tr></table></figure>
<h2 id="4-RDD"><a href="#4-RDD" class="headerlink" title="4 RDD"></a>4 RDD</h2><h3 id="1-创建"><a href="#1-创建" class="headerlink" title="(1) 创建"></a>(1) 创建</h3><p>RDD有两种生成方式：并行化驱动程序中的集合，从Hadoop支持的外部数据源导入</p>
<h4 id="1-并行化集合"><a href="#1-并行化集合" class="headerlink" title="1) 并行化集合"></a>1) 并行化集合</h4><p>使用SparkContext.parallelize()并行化驱动程序上的已有数据集合。</p>
<p>可以指定数据分区(partition或slice)数量。计算时，Spark为每一个分区分配一个任务。Spark默认基于集群分配。也可以在参数中显式分配。通常为每个CPU分配2-4个分区。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> data = <span class="type">Array</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>)</span><br><span class="line"><span class="keyword">val</span> distData = sc.parallelize(data)</span><br></pre></td></tr></table></figure>
<h4 id="2-外部数据集"><a href="#2-外部数据集" class="headerlink" title="2) 外部数据集"></a>2) 外部数据集</h4><p>支持所有Hadoop InputFormat，可以在参数中指定分区数量。对于HDFS默认按照块(默认128MB)数量分区。</p>
<p>本地文件：使用本地路径时，需要所有worker具有相同路径的文件</p>
<p>文本文件：SparkContext.wholeTextFiles可以按照目录读入文本文件，返回(filename, content)键值对。</p>
<p>SequenceFile：使用SparkContext.sequenceFile[K, V]读入。K和V是Hadoop中Writable 接口的子类。对于原生类型，自动转换为对应类。如sequenceFile[Int, String] - &gt; sequenceFile[IntWritables, Text]。</p>
<p>其他格式的Hadoop文件：使用SparkContext.hadoopRDD或新的接口SparkContext.newAPIHadoopRDD。</p>
<p>RDD.saveAsObjectFile和SparkContext.objectFile支持以序列化Java对象的格式保存RDD，但是没有Avro高效。</p>
<h3 id="2-操作"><a href="#2-操作" class="headerlink" title="(2) 操作"></a>(2) 操作</h3><p>RDD支持两种操作：转换和动作。</p>
<p>转换将RDD从已有数据集转换到新的数据集。动作通过计算数据集，返回值给驱动程序。</p>
<p>所有的转换都是惰性的。为了提高效率，只有当动作使用相应的数据时才计算。</p>
<p>为了避免重复计算，可以使用persist或cache中间转换结果RDD。</p>
<h4 id="1-基础"><a href="#1-基础" class="headerlink" title="1) 基础"></a>1) 基础</h4><p>示例</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 读入也是惰性的</span></span><br><span class="line">val lines = sc.textFile(<span class="string">"data.txt"</span>)</span><br><span class="line"><span class="comment">// 惰性</span></span><br><span class="line">val lineLengths = lines.map(s =&gt; s.length)</span><br><span class="line"><span class="comment">// 首次计算后即缓存</span></span><br><span class="line">lineLengths.persist()</span><br><span class="line"><span class="comment">// 触发计算链路</span></span><br><span class="line">val totalLength = lineLengths.reduce((a, b) =&gt; a + b)</span><br></pre></td></tr></table></figure>
<h4 id="2-函数传递"><a href="#2-函数传递" class="headerlink" title="2) 函数传递"></a>2) 函数传递</h4><p>Spark十分依赖于在驱动程序中函数传递以在集群上运行。推荐使用以下两种方式：</p>
<ul>
<li>匿名函数</li>
<li>全局单例对象的静态方法，如下：</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">MyFunctions</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">func1</span></span>(s: <span class="type">String</span>): <span class="type">String</span> = &#123; ... &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">myRdd.map(<span class="type">MyFunctions</span>.func1)</span><br></pre></td></tr></table></figure>
<p>可以传递一个类实例的方法引用的方式实现：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// map中引用对象方法func1，需要将整个MyClass对象发送到集群中 </span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyClass</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">func1</span></span>(s: <span class="type">String</span>): <span class="type">String</span> = &#123; ... &#125;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">doStuff</span></span>(rdd: <span class="type">RDD</span>[<span class="type">String</span>]): <span class="type">RDD</span>[<span class="type">String</span>] = &#123; rdd.map(func1) &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 等效于rdd.map(x =&gt; this.func1(x))</span></span><br><span class="line"><span class="keyword">new</span> <span class="type">MyClass</span>().doStuff(myRdd)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 同上，map中引用外部对象字段，需要将整个对象发送到集群中</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyClass</span> </span>&#123;</span><br><span class="line">  <span class="keyword">val</span> field = <span class="string">"Hello"</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">doStuff</span></span>(rdd: <span class="type">RDD</span>[<span class="type">String</span>]): <span class="type">RDD</span>[<span class="type">String</span>] = &#123; rdd.map(x =&gt; field + x) &#125;</span><br><span class="line"><span class="comment">// 等效于rdd.map(x =&gt; this.field + x)</span></span><br><span class="line"><span class="keyword">new</span> <span class="type">MyClass</span>().doStuff(myRdd)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 拷贝到局部变量中，避免每次map运算时都发送整个对象    </span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyClass</span> </span>&#123;</span><br><span class="line">  <span class="keyword">val</span> field = <span class="string">"Hello"</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">doStuff</span></span>(rdd: <span class="type">RDD</span>[<span class="type">String</span>]): <span class="type">RDD</span>[<span class="type">String</span>] = &#123;</span><br><span class="line">  	<span class="keyword">val</span> field_ = <span class="keyword">this</span>.field</span><br><span class="line">  	rdd.map(x =&gt; field_ + x)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">new</span> <span class="type">MyClass</span>().doStuff(myRdd)</span><br></pre></td></tr></table></figure>
<h4 id="3-闭包"><a href="#3-闭包" class="headerlink" title="3) 闭包"></a>3) 闭包</h4><p>集群执行代码时，理解变量的作用域和生命周期是个难点。</p>
<p>以下以foreach()中增加计数器为例：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 反例</span></span><br><span class="line"><span class="comment">// 结果与是否在同一JVM中执行有关</span></span><br><span class="line"><span class="keyword">var</span> counter = <span class="number">0</span></span><br><span class="line"><span class="keyword">var</span> rdd = sc.parallelize(data)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Wrong: Don't do this!!</span></span><br><span class="line">rdd.foreach(x =&gt; counter += x)</span><br><span class="line"></span><br><span class="line">println(<span class="string">"Counter value: "</span> + counter)</span><br></pre></td></tr></table></figure>
<h5 id="1’-本地vs集群"><a href="#1’-本地vs集群" class="headerlink" title="1’ 本地vs集群"></a>1’ 本地vs集群</h5><p>闭包是在执行器计算时必须可见的变量和方法。闭包被序列化并发送给每一个执行器。</p>
<p>当闭包内使用外部对象时，使用的是副本，对于原来的数据没有影响。</p>
<p>虽然在本地同一JVM下执行可能正确，但是不推荐。</p>
<p>建议使用累加器。</p>
<h5 id="2‘-打印RDD元素"><a href="#2‘-打印RDD元素" class="headerlink" title="2‘ 打印RDD元素"></a>2‘ 打印RDD元素</h5><p>集群模式时，标准输出是在执行器本地。</p>
<ul>
<li>使用collect()，将整个RDD返回到驱动节点。但可能耗尽驱动节点内存。</li>
<li>使用take()获取指定量的元素到驱动节点</li>
</ul>
<h4 id="4-键值对"><a href="#4-键值对" class="headerlink" title="4) 键值对"></a>4) 键值对</h4><p>Scala中，使用<a href="https://www.scala-lang.org/api/2.12.10/scala/Tuple2.html" target="_blank" rel="noopener">Tuple2</a>实现，键值对操作在类 <a href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.PairRDDFunctions" target="_blank" rel="noopener">PairRDDFunctions</a>中。</p>
<p>注意：使用自定义对象，需要实现hashcode()和equals()。详见<a href="https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html#hashCode--" target="_blank" rel="noopener">Object.hashCode() documentation</a>.</p>
<h4 id="5-转换"><a href="#5-转换" class="headerlink" title="5) 转换"></a>5) 转换</h4><p>详见RDD API doc (<a href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.RDD" target="_blank" rel="noopener">Scala</a>, <a href="http://spark.apache.org/docs/latest/api/java/index.html?org/apache/spark/api/java/JavaRDD.html" target="_blank" rel="noopener">Java</a>, <a href="http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD" target="_blank" rel="noopener">Python</a>, <a href="http://spark.apache.org/docs/latest/api/R/index.html" target="_blank" rel="noopener">R</a>)和pair RDD functions doc (<a href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.PairRDDFunctions" target="_blank" rel="noopener">Scala</a>, <a href="http://spark.apache.org/docs/latest/api/java/index.html?org/apache/spark/api/java/JavaPairRDD.html" target="_blank" rel="noopener">Java</a>)</p>
<p><img src="/2020/05/26/200526RDD入门/image-20200602175340948.png" alt="image-20200602175340948"></p>
<h4 id="6-动作"><a href="#6-动作" class="headerlink" title="6) 动作"></a>6) 动作</h4><p>详见RDD API doc (<a href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.RDD" target="_blank" rel="noopener">Scala</a>, <a href="http://spark.apache.org/docs/latest/api/java/index.html?org/apache/spark/api/java/JavaRDD.html" target="_blank" rel="noopener">Java</a>, <a href="http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD" target="_blank" rel="noopener">Python</a>, <a href="http://spark.apache.org/docs/latest/api/R/index.html" target="_blank" rel="noopener">R</a>)和pair RDD functions doc (<a href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.PairRDDFunctions" target="_blank" rel="noopener">Scala</a>, <a href="http://spark.apache.org/docs/latest/api/java/index.html?org/apache/spark/api/java/JavaPairRDD.html" target="_blank" rel="noopener">Java</a>)</p>
<p><img src="/2020/05/26/200526RDD入门/image-20200602204104723.png" alt="image-20200602204104723"></p>
<p>Spark暴露了一些动作的异步形式，如foreach()对应的foreachAsync()。调用后立即返回FutureAction，而不是阻塞直到完成。</p>
<h4 id="7-shuffle"><a href="#7-shuffle" class="headerlink" title="7) shuffle"></a>7) shuffle</h4><p>一种复杂且代价昂贵的操作，通常用于数据在节点间的再分区。</p>
<h5 id="1‘-背景"><a href="#1‘-背景" class="headerlink" title="1‘ 背景"></a>1‘ 背景</h5><p>以reduceByKey为例，其将键名和所有具有相同键名的键值作为一个元组处理。但是这些键值通常分布在各个分区中。Spark中分区位置又与操作无关，因此需要读取所有分区的所有值，并将具有相同键名的键值汇聚到一起。</p>
<p>shuffle后的数据分区间的排序是确定的，但是分区内不确定。若要实现分区内排序，需要额外的操作：</p>
<ul>
<li>使用mapPartition对各分区排序</li>
<li>使用repartitionAndSortWithinPartitions 在分区同时分区内排序</li>
<li>使用sortBy全局排序</li>
</ul>
<p>常见的shuffle操作有再分区( <a href="http://spark.apache.org/docs/latest/rdd-programming-guide.html#RepartitionLink" target="_blank" rel="noopener">repartition</a> 和<a href="http://spark.apache.org/docs/latest/rdd-programming-guide.html#CoalesceLink" target="_blank" rel="noopener">coalesce</a>)、按键（计数除外，<a href="http://spark.apache.org/docs/latest/rdd-programming-guide.html#GroupByLink" target="_blank" rel="noopener">groupByKey</a>和<a href="http://spark.apache.org/docs/latest/rdd-programming-guide.html#ReduceByLink" target="_blank" rel="noopener">reduceByKey</a>）和连接（<a href="http://spark.apache.org/docs/latest/rdd-programming-guide.html#CogroupLink" target="_blank" rel="noopener">cogroup</a> and <a href="http://spark.apache.org/docs/latest/rdd-programming-guide.html#JoinLink" target="_blank" rel="noopener">join</a>）</p>
<h5 id="2’-性能影响"><a href="#2’-性能影响" class="headerlink" title="2’ 性能影响"></a>2’ 性能影响</h5><p>shuffle涉及到磁盘IO、序列化和网络IO，代价昂贵。</p>
<p>继承自MapReduce(与Spark的map()/reduce()没有直接联系)，map任务负责组织数据，reduce任务负责聚合数据。在内部，map任务间结果保存在内存中（直到满溢），然后基于目标分区排序并写出到单个文件；reduce任务从排序的块中读取。</p>
<p>因为数据传输前后在内存中组织数据结构，shuffle占用大量堆内存。对于reduceByKey和aggregateByKey在map任务是创建数据结构（推荐原因，在map处已聚合），而其他ByKey操作在reduce任务处。当内存不足时，会引起额外的磁盘IO和垃圾回收。</p>
<p>同时，shuffle在磁盘上产生大量的中间文件。对于版本1.3，这些文件将保存到相应的RDD被回收。虽然可避免重算重复产生，但是如果长期引用或回收不及时，将消耗大量的磁盘空间。临时文件存储目录通过spark.local.dir配置。</p>
<p>可以通过修改配置减少shuffle损耗，详见<a href="http://spark.apache.org/docs/latest/configuration.html" target="_blank" rel="noopener">Spark Configuration Guide</a>中Shuffle Behavior一节。</p>
<h3 id="3-持久化"><a href="#3-持久化" class="headerlink" title="(3) 持久化"></a>(3) 持久化</h3><p>为了快速计算和避免重算，利于迭代和快速交互，可以缓存数据集。</p>
<p>cache()仅存储到内存，persist()可以选择存储级别。</p>
<p>为了避免shuffle时节点失效引起的重算，Spark自动将某些中间数据缓存。</p>
<p><img src="/2020/05/26/200526RDD入门/image-20200607152307918.png" alt="image-20200607152307918"></p>
<p>存储等级选择：</p>
<ul>
<li>优先仅内存，除非空间不足。</li>
<li>内存空间不足时，使用内存序列化等级，选择合适的<a href="http://spark.apache.org/docs/latest/tuning.html" target="_blank" rel="noopener">序列化库</a>压缩</li>
<li>除非海量数据或重算代价很高，不选择磁盘等级</li>
<li>为了快速容错恢复，使用副本等级</li>
</ul>
<p>Spark使用LRU算法自动移除缓存，或者使用unpersist()人为移除</p>
<h2 id="5-共享变量"><a href="#5-共享变量" class="headerlink" title="5 共享变量"></a>5 共享变量</h2><p>普通变量拷贝到执行节点后，变量变化不会与其他节点同步。</p>
<p>Spark提供两种共享变量：广播变量和累加器。</p>
<h3 id="1-广播变量"><a href="#1-广播变量" class="headerlink" title="(1) 广播变量"></a>(1) 广播变量</h3><p>广播变量是缓存在每个节点上的只读数据。</p>
<p>通常用于分发大量输入数据。</p>
<p>Spark自动将任务所需通用数据广播。这些数据以序列化形式缓存，并在任务执行前反序列化。因此，广播变量只在以下场景有用：多个阶段的任务需要同样的数据、数据需要以反序列化的形式缓存。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> broadcastVar = sc.broadcast(<span class="type">Array</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line">broadcastVar: org.apache.spark.broadcast.<span class="type">Broadcast</span>[<span class="type">Array</span>[<span class="type">Int</span>]] = <span class="type">Broadcast</span>(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; broadcastVar.value</span><br><span class="line">res0: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<p>此外，广播变量中的对象v不应该再变动，为了保证所有节点获取到相同的数据。</p>
<h3 id="2-累加器"><a href="#2-累加器" class="headerlink" title="(2) 累加器"></a>(2) 累加器</h3><p>累加器只能累加，可用于计数或加和。</p>
<p>Spark原生支持数值类型，其他类型需要人为实现。</p>
<p>阶段或任务中使用的累加器将在对应的WebUI中展示。</p>
<p>Spark通过SparkContext中对应的累加器方法创建不同数据类型的累加器。</p>
<p>任务调用add()方法加和，只能写，不能读。</p>
<p>驱动程序可以读取累加器值。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> accum = sc.longAccumulator(<span class="string">"My Accumulator"</span>)</span><br><span class="line">accum: org.apache.spark.util.<span class="type">LongAccumulator</span> = <span class="type">LongAccumulator</span>(id: <span class="number">0</span>, name: <span class="type">Some</span>(<span class="type">My</span> <span class="type">Accumulator</span>), value: <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; sc.parallelize(<span class="type">Array</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)).foreach(x =&gt; accum.add(x))</span><br><span class="line">...</span><br><span class="line"><span class="number">10</span>/<span class="number">09</span>/<span class="number">29</span> <span class="number">18</span>:<span class="number">41</span>:<span class="number">08</span> <span class="type">INFO</span> <span class="type">SparkContext</span>: <span class="type">Tasks</span> finished in <span class="number">0.317106</span> s</span><br><span class="line"></span><br><span class="line">scala&gt; accum.value</span><br><span class="line">res2: <span class="type">Long</span> = <span class="number">10</span></span><br></pre></td></tr></table></figure>
<p>通过<a href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.util.AccumulatorV2" target="_blank" rel="noopener">AccumulatorV2</a>实现自定义的累加器</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VectorAccumulatorV2</span> <span class="keyword">extends</span> <span class="title">AccumulatorV2</span>[<span class="type">MyVector</span>, <span class="type">MyVector</span>] </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> myVector: <span class="type">MyVector</span> = <span class="type">MyVector</span>.createZeroVector</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">reset</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">    myVector.reset()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">add</span></span>(v: <span class="type">MyVector</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    myVector.add(v)</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Then, create an Accumulator of this type:</span></span><br><span class="line"><span class="keyword">val</span> myVectorAcc = <span class="keyword">new</span> <span class="type">VectorAccumulatorV2</span></span><br><span class="line"><span class="comment">// Then, register it into spark context:</span></span><br><span class="line">sc.register(myVectorAcc, <span class="string">"MyVectorAcc1"</span>)</span><br></pre></td></tr></table></figure>
<p>注意：Spark保证动作操作中，每个任务值更新累加器刚好一次，即使重启任务。而转换操作中，需要避免多次更新。</p>
<p>累加器不影响惰性计算。需要动作操作触发，才能实现转换操作中的累加器更新。</p>
<p>如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> accum = sc.longAccumulator</span><br><span class="line">data.map &#123; x =&gt; accum.add(x); x &#125;</span><br><span class="line"><span class="comment">// Here, accum is still 0 because no actions have caused the map operation to be computed.</span></span><br></pre></td></tr></table></figure>
<h2 id="6-集群部署"><a href="#6-集群部署" class="headerlink" title="6 集群部署"></a>6 集群部署</h2><p>详见 <a href="http://spark.apache.org/docs/latest/submitting-applications.html" target="_blank" rel="noopener">application submission guide</a></p>
<h2 id="7-Java-Scala启动"><a href="#7-Java-Scala启动" class="headerlink" title="7 Java/Scala启动"></a>7 Java/Scala启动</h2><p>使用Java将Spark作业作为子进程运行，详见<a href="http://spark.apache.org/docs/latest/api/java/index.html?org/apache/spark/launcher/package-summary.html" target="_blank" rel="noopener">org.apache.spark.launcher</a></p>
<h2 id="8-单元测试"><a href="#8-单元测试" class="headerlink" title="8 单元测试"></a>8 单元测试</h2><p>Spark支持常见的单元测试框架。</p>
<p>创建本地模式的SparkContext执行操作。</p>
<p>由于Spark不支持在同一项目中运行两个上下文，测试完成后，在finally语句块或框架teardown()方法中调用SparkContext.stop()终止。</p>
<h2 id="9-学习指引"><a href="#9-学习指引" class="headerlink" title="9 学习指引"></a>9 学习指引</h2><p><a href="https://spark.apache.org/examples.html" target="_blank" rel="noopener">示例程序</a>详见(<a href="https://github.com/apache/spark/tree/master/examples/src/main/scala/org/apache/spark/examples" target="_blank" rel="noopener">Scala</a>, <a href="https://github.com/apache/spark/tree/master/examples/src/main/java/org/apache/spark/examples" target="_blank" rel="noopener">Java</a>, <a href="https://github.com/apache/spark/tree/master/examples/src/main/python" target="_blank" rel="noopener">Python</a>, <a href="https://github.com/apache/spark/tree/master/examples/src/main/r" target="_blank" rel="noopener">R</a>)</p>
<p>最佳实践详见 <a href="http://spark.apache.org/docs/latest/configuration.html" target="_blank" rel="noopener">configuration</a>和<a href="http://spark.apache.org/docs/latest/tuning.html" target="_blank" rel="noopener">tuning</a></p>
<p>集群部署详见<a href="http://spark.apache.org/docs/latest/cluster-overview.html" target="_blank" rel="noopener">cluster mode overview</a></p>
<p>完整API详见<a href="http://spark.apache.org/docs/latest/api/scala/#org.apache.spark.package" target="_blank" rel="noopener">Scala</a>, <a href="http://spark.apache.org/docs/latest/api/java/" target="_blank" rel="noopener">Java</a>, <a href="http://spark.apache.org/docs/latest/api/python/" target="_blank" rel="noopener">Python</a> , <a href="http://spark.apache.org/docs/latest/api/R/" target="_blank" rel="noopener">R</a></p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="http://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener">RDD Programming Guide</a></p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/RDD/" rel="tag"># RDD</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/05/26/200526RDD源码/" rel="next" title="RDD源码">
                <i class="fa fa-chevron-left"></i> RDD源码
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2020/05/26/200526HashMap/" rel="prev" title="HashMap(JDK 14)">
                HashMap(JDK 14) <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.jpg"
                alt="Hopeful Nick" />
            
              <p class="site-author-name" itemprop="name">Hopeful Nick</p>
              <p class="site-description motion-element" itemprop="description">To Explore</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">96</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                
                  <span class="site-state-item-count">28</span>
                  <span class="site-state-item-name">分类</span>
                
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">33</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/hopefulnick" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:lh848764@gmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-概览"><span class="nav-number">1.</span> <span class="nav-text">1 概览</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-连接Spark"><span class="nav-number">2.</span> <span class="nav-text">2 连接Spark</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-初始化Spark"><span class="nav-number">3.</span> <span class="nav-text">3 初始化Spark</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-应用程序"><span class="nav-number">3.1.</span> <span class="nav-text">(1) 应用程序</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-交互命令行"><span class="nav-number">3.2.</span> <span class="nav-text">(2) 交互命令行</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-RDD"><span class="nav-number">4.</span> <span class="nav-text">4 RDD</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-创建"><span class="nav-number">4.1.</span> <span class="nav-text">(1) 创建</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-并行化集合"><span class="nav-number">4.1.1.</span> <span class="nav-text">1) 并行化集合</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-外部数据集"><span class="nav-number">4.1.2.</span> <span class="nav-text">2) 外部数据集</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-操作"><span class="nav-number">4.2.</span> <span class="nav-text">(2) 操作</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-基础"><span class="nav-number">4.2.1.</span> <span class="nav-text">1) 基础</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-函数传递"><span class="nav-number">4.2.2.</span> <span class="nav-text">2) 函数传递</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-闭包"><span class="nav-number">4.2.3.</span> <span class="nav-text">3) 闭包</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1’-本地vs集群"><span class="nav-number">4.2.3.1.</span> <span class="nav-text">1’ 本地vs集群</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2‘-打印RDD元素"><span class="nav-number">4.2.3.2.</span> <span class="nav-text">2‘ 打印RDD元素</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-键值对"><span class="nav-number">4.2.4.</span> <span class="nav-text">4) 键值对</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-转换"><span class="nav-number">4.2.5.</span> <span class="nav-text">5) 转换</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-动作"><span class="nav-number">4.2.6.</span> <span class="nav-text">6) 动作</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-shuffle"><span class="nav-number">4.2.7.</span> <span class="nav-text">7) shuffle</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1‘-背景"><span class="nav-number">4.2.7.1.</span> <span class="nav-text">1‘ 背景</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2’-性能影响"><span class="nav-number">4.2.7.2.</span> <span class="nav-text">2’ 性能影响</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-持久化"><span class="nav-number">4.3.</span> <span class="nav-text">(3) 持久化</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-共享变量"><span class="nav-number">5.</span> <span class="nav-text">5 共享变量</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-广播变量"><span class="nav-number">5.1.</span> <span class="nav-text">(1) 广播变量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-累加器"><span class="nav-number">5.2.</span> <span class="nav-text">(2) 累加器</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-集群部署"><span class="nav-number">6.</span> <span class="nav-text">6 集群部署</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-Java-Scala启动"><span class="nav-number">7.</span> <span class="nav-text">7 Java/Scala启动</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#8-单元测试"><span class="nav-number">8.</span> <span class="nav-text">8 单元测试</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#9-学习指引"><span class="nav-number">9.</span> <span class="nav-text">9 学习指引</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参考资料"><span class="nav-number">10.</span> <span class="nav-text">参考资料</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Hopeful Nick</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  

    
      <script id="dsq-count-scr" src="https://hopefulnick.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'https://hopefulnick.github.io/2020/05/26/200526RDD入门/';
          this.page.identifier = '2020/05/26/200526RDD入门/';
          this.page.title = 'RDD入门';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://hopefulnick.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  














  





  

  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  

  

  

  

</body>
</html>
