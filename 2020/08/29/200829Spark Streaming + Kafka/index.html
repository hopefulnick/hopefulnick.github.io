<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon32.jpg?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon16.jpg?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Spark," />










<meta name="description" content="适用于版本3.0.1。 新的消费者API 提供并行的、Kafka分区与Spark分区1:1、可以访问偏移和元数据的方式。与旧版本直接API在使用方式上不同。">
<meta name="keywords" content="Spark">
<meta property="og:type" content="article">
<meta property="og:title" content="Spark Streaming + Kafka">
<meta property="og:url" content="https://hopefulnick.github.io/2020/08/29/200829Spark Streaming + Kafka/index.html">
<meta property="og:site_name" content="Hopeful Nick">
<meta property="og:description" content="适用于版本3.0.1。 新的消费者API 提供并行的、Kafka分区与Spark分区1:1、可以访问偏移和元数据的方式。与旧版本直接API在使用方式上不同。">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2020-11-18T05:11:40.333Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Spark Streaming + Kafka">
<meta name="twitter:description" content="适用于版本3.0.1。 新的消费者API 提供并行的、Kafka分区与Spark分区1:1、可以访问偏移和元数据的方式。与旧版本直接API在使用方式上不同。">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://hopefulnick.github.io/2020/08/29/200829Spark Streaming + Kafka/"/>





  <title>Spark Streaming + Kafka | Hopeful Nick</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hopeful Nick</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://hopefulnick.github.io/2020/08/29/200829Spark Streaming + Kafka/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Hopeful Nick">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hopeful Nick">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Spark Streaming + Kafka</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-08-29T21:00:47+08:00">
                2020-08-29
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Spark/" itemprop="url" rel="index">
                    <span itemprop="name">Spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/08/29/200829Spark Streaming + Kafka/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2020/08/29/200829Spark Streaming + Kafka/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>适用于版本3.0.1。</p>
<p><a href="https://kafka.apache.org/documentation.html#newconsumerapi" target="_blank" rel="noopener">新的消费者API</a> 提供并行的、Kafka分区与Spark分区1:1、可以访问偏移和元数据的方式。与<a href="https://spark.apache.org/docs/2.3.0/streaming-kafka-0-8-integration.html#approach-2-direct-approach-no-receivers" target="_blank" rel="noopener">旧版本</a>直接API在使用方式上不同。</p>
<a id="more"></a>
<h2 id="1-连接"><a href="#1-连接" class="headerlink" title="1 连接"></a>1 连接</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">groupId = org.apache.spark</span><br><span class="line">artifactId = spark-streaming-kafka-0-10_2.12</span><br><span class="line">version = 3.0.1</span><br></pre></td></tr></table></figure>
<p>注意：不要直接引用kafka依赖。因为spark使用了过渡性依赖，影响了诊断方式的兼容性。</p>
<h2 id="2-创建直接流"><a href="#2-创建直接流" class="headerlink" title="2 创建直接流"></a>2 创建直接流</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.<span class="type">ConsumerRecord</span></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.<span class="type">StringDeserializer</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.kafka010._</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.kafka010.<span class="type">LocationStrategies</span>.<span class="type">PreferConsistent</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.kafka010.<span class="type">ConsumerStrategies</span>.<span class="type">Subscribe</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> kafkaParams = <span class="type">Map</span>[<span class="type">String</span>, <span class="type">Object</span>](</span><br><span class="line">  <span class="string">"bootstrap.servers"</span> -&gt; <span class="string">"localhost:9092,anotherhost:9092"</span>,</span><br><span class="line">  <span class="string">"key.deserializer"</span> -&gt; classOf[<span class="type">StringDeserializer</span>],</span><br><span class="line">  <span class="string">"value.deserializer"</span> -&gt; classOf[<span class="type">StringDeserializer</span>],</span><br><span class="line">  <span class="string">"group.id"</span> -&gt; <span class="string">"use_a_separate_group_id_for_each_stream"</span>,</span><br><span class="line">  <span class="string">"auto.offset.reset"</span> -&gt; <span class="string">"latest"</span>,</span><br><span class="line">  <span class="string">"enable.auto.commit"</span> -&gt; (<span class="literal">false</span>: java.lang.<span class="type">Boolean</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> topics = <span class="type">Array</span>(<span class="string">"topicA"</span>, <span class="string">"topicB"</span>)</span><br><span class="line"><span class="keyword">val</span> stream = <span class="type">KafkaUtils</span>.createDirectStream[<span class="type">String</span>, <span class="type">String</span>](</span><br><span class="line">  streamingContext,</span><br><span class="line">  <span class="type">PreferConsistent</span>,</span><br><span class="line">  <span class="type">Subscribe</span>[<span class="type">String</span>, <span class="type">String</span>](topics, kafkaParams)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">stream.map(record =&gt; (record.key, record.value))</span><br></pre></td></tr></table></figure>
<p>每个记录是一个<a href="http://kafka.apache.org/0100/javadoc/org/apache/kafka/clients/consumer/ConsumerRecord.html" target="_blank" rel="noopener">ConsumerRecord</a>对象。</p>
<p>更多配置详见<a href="http://kafka.apache.org/documentation.html#newconsumerconfigs" target="_blank" rel="noopener">Kafka consumer config docs</a></p>
<p>当批处理间隔大于Kafka默认的心跳会话超时（30s）时，需要增加heartbeat.interval.ms 和session.timeout.ms。</p>
<p>批处理间隔超过5min，还需要改变中介上的group.max.session.timeout.ms。</p>
<p>提交策略详见<a href="https://spark.apache.org/docs/latest/streaming-kafka-0-10-integration.html#storing-offsets" target="_blank" rel="noopener">Storing Offsets</a>。</p>
<h2 id="3-位置策略"><a href="#3-位置策略" class="headerlink" title="3 位置策略"></a>3 位置策略</h2><p>新API会预提取消息到缓冲中。为了提升性能，Spark会在执行器上缓存消费者（spark.streaming.kafka.consumer.cache.enabled），倾向于调度分区到相应的消费者位置。</p>
<ul>
<li><p>PreferConsistent平均分配分区到执行器上，适合大多数场景；</p>
</li>
<li><p>PreferBrokers调度分区到leader所在的节点，适合执行器和broker处于相同节点；</p>
</li>
<li><p>PreferFixed允许显式执行分区-主机映射，其余平均分配，适合数据倾斜场景。</p>
</li>
</ul>
<p>默认最大消费者缓存上限为64。如果需要处理超过64 * number of executors个分区，可以设置spark.streaming.kafka.consumer.cache.maxCapacity。</p>
<p>缓存通过主题分区和group.id识别，因此需要为每次调用createDirectStream，使用不同的group.id。</p>
<h2 id="4-消费策略"><a href="#4-消费策略" class="headerlink" title="4 消费策略"></a>4 消费策略</h2><p>ConsumerStrategies 允许Spark即使从检查点重启，也可以获取配置的消费者。</p>
<ul>
<li>Subscribe订阅固定的主题集合</li>
<li>SubscribePattern使用正则指定主题，需要注意响应新加的主题分区</li>
<li>Assign订阅固定的分区集合</li>
</ul>
<p>以上方式都可以在构造器中指定偏移。</p>
<p>ConsumerStrategy可以自定义扩展。</p>
<h2 id="5-创建RDD"><a href="#5-创建RDD" class="headerlink" title="5 创建RDD"></a>5 创建RDD</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Import dependencies and create kafka params as in Create Direct Stream above</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> offsetRanges = <span class="type">Array</span>(</span><br><span class="line">  <span class="comment">// topic, partition, inclusive starting offset, exclusive ending offset</span></span><br><span class="line">  <span class="type">OffsetRange</span>(<span class="string">"test"</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">100</span>),</span><br><span class="line">  <span class="type">OffsetRange</span>(<span class="string">"test"</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">100</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> rdd = <span class="type">KafkaUtils</span>.createRDD[<span class="type">String</span>, <span class="type">String</span>](sparkContext, kafkaParams, offsetRanges, <span class="type">PreferConsistent</span>)</span><br></pre></td></tr></table></figure>
<p>适用于离线处理消息，通过执行主题、分区和偏移。</p>
<p>注意：</p>
<p>不能使用PreferBrokers，因为流场景以外，没有驱动端的消费者自动查找元数据。如果需要，使用PreferFixed和自定义的元数据查找。</p>
<h2 id="6-获取偏移"><a href="#6-获取偏移" class="headerlink" title="6 获取偏移"></a>6 获取偏移</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">stream.foreachRDD &#123; rdd =&gt;</span><br><span class="line">  <span class="keyword">val</span> offsetRanges = rdd.asInstanceOf[<span class="type">HasOffsetRanges</span>].offsetRanges</span><br><span class="line">  rdd.foreachPartition &#123; iter =&gt;</span><br><span class="line">    <span class="keyword">val</span> o: <span class="type">OffsetRange</span> = offsetRanges(<span class="type">TaskContext</span>.get.partitionId)</span><br><span class="line">    println(<span class="string">s"<span class="subst">$&#123;o.topic&#125;</span> <span class="subst">$&#123;o.partition&#125;</span> <span class="subst">$&#123;o.fromOffset&#125;</span> <span class="subst">$&#123;o.untilOffset&#125;</span>"</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注意：</p>
<ul>
<li>HasOffsetRanges类型转换仅在createDirectStream创建后的第一个方法调用中成功。</li>
<li>RDD与Kafka分区一对一关系仅在shuffle或repartition前成立。</li>
</ul>
<h2 id="7-保存偏移"><a href="#7-保存偏移" class="headerlink" title="7 保存偏移"></a>7 保存偏移</h2><p>Kafka消息传递语义取决于偏移的存储方式和时机。Spark输出保证了<a href="https://spark.apache.org/docs/latest/streaming-programming-guide.html#semantics-of-output-operations" target="_blank" rel="noopener">至少一次</a>语义。</p>
<p>想要实现刚好一次语义，必须实现以下一项：</p>
<ul>
<li>在幂等输出后保存偏移</li>
<li>输出时在原子性事务中保存偏移</li>
</ul>
<p>存储偏移主要有以下3种方式：</p>
<h3 id="1-检查点"><a href="#1-检查点" class="headerlink" title="(1) 检查点"></a>(1) 检查点</h3><p>偏移将被保存在检查点中。</p>
<p>但是需要保证输出的幂等性，并且不能在代码变更后恢复检查点。</p>
<p>计划的代码更新可以同时运行新旧代码并保持输出幂等；而计划外的需要识别开始的偏移。</p>
<h3 id="2-Kafka"><a href="#2-Kafka" class="headerlink" title="(2) Kafka"></a>(2) Kafka</h3><p>Kafka默认在消费者poll()成功后自动提交偏移。</p>
<p>可以使用异步提交commitAsync()在确认输出后提交偏移。</p>
<p>因为Kafka不是事务性，所以输出需要幂等。？</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">stream.foreachRDD &#123; rdd =&gt;</span><br><span class="line">  <span class="keyword">val</span> offsetRanges = rdd.asInstanceOf[<span class="type">HasOffsetRanges</span>].offsetRanges</span><br><span class="line"></span><br><span class="line">  <span class="comment">// some time later, after outputs have completed</span></span><br><span class="line">  stream.asInstanceOf[<span class="type">CanCommitOffsets</span>].commitAsync(offsetRanges)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注意：由于HasOffsetRanges的原因，CanCommitOffsets类型转换只对createDirectStream的结果有效。</p>
<h3 id="3-自定义"><a href="#3-自定义" class="headerlink" title="(3) 自定义"></a>(3) 自定义</h3><p>实现支持事务的偏移存储。</p>
<p>尤其针对难以幂等的聚合输出。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// The details depend on your data store, but the general idea looks like this</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// begin from the offsets committed to the database</span></span><br><span class="line"><span class="keyword">val</span> fromOffsets = selectOffsetsFromYourDatabase.map &#123; resultSet =&gt;</span><br><span class="line">  <span class="keyword">new</span> <span class="type">TopicPartition</span>(resultSet.string(<span class="string">"topic"</span>), resultSet.int(<span class="string">"partition"</span>)) -&gt; resultSet.long(<span class="string">"offset"</span>)</span><br><span class="line">&#125;.toMap</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> stream = <span class="type">KafkaUtils</span>.createDirectStream[<span class="type">String</span>, <span class="type">String</span>](</span><br><span class="line">  streamingContext,</span><br><span class="line">  <span class="type">PreferConsistent</span>,</span><br><span class="line">  <span class="type">Assign</span>[<span class="type">String</span>, <span class="type">String</span>](fromOffsets.keys.toList, kafkaParams, fromOffsets)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">stream.foreachRDD &#123; rdd =&gt;</span><br><span class="line">  <span class="keyword">val</span> offsetRanges = rdd.asInstanceOf[<span class="type">HasOffsetRanges</span>].offsetRanges</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> results = yourCalculation(rdd)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// begin your transaction</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// update results</span></span><br><span class="line">  <span class="comment">// update offsets where the end of existing offsets matches the beginning of this batch of offsets</span></span><br><span class="line">  <span class="comment">// assert that offsets were updated correctly</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// end your transaction</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="8-SSL-TLS"><a href="#8-SSL-TLS" class="headerlink" title="8 SSL/TLS"></a>8 SSL/TLS</h2><p>新的Kafka消费者API支持<a href="http://kafka.apache.org/documentation.html#security_ssl" target="_blank" rel="noopener">SSL</a>，仅用于Spark与Kafka之间的通信，内部节点间需要另外实现。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> kafkaParams = <span class="type">Map</span>[<span class="type">String</span>, <span class="type">Object</span>](</span><br><span class="line">  <span class="comment">// the usual params, make sure to change the port in bootstrap.servers if 9092 is not TLS</span></span><br><span class="line">  <span class="string">"security.protocol"</span> -&gt; <span class="string">"SSL"</span>,</span><br><span class="line">  <span class="string">"ssl.truststore.location"</span> -&gt; <span class="string">"/some-directory/kafka.client.truststore.jks"</span>,</span><br><span class="line">  <span class="string">"ssl.truststore.password"</span> -&gt; <span class="string">"test1234"</span>,</span><br><span class="line">  <span class="string">"ssl.keystore.location"</span> -&gt; <span class="string">"/some-directory/kafka.client.keystore.jks"</span>,</span><br><span class="line">  <span class="string">"ssl.keystore.password"</span> -&gt; <span class="string">"test1234"</span>,</span><br><span class="line">  <span class="string">"ssl.key.password"</span> -&gt; <span class="string">"test1234"</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h2 id="9-部署"><a href="#9-部署" class="headerlink" title="9 部署"></a>9 部署</h2><p>将spark-streaming-kafka-0-10_2.12及其依赖打包</p>
<p>将spark-core_2.12和spark-streaming_2.12标记为provided</p>
<p>详见<a href="https://spark.apache.org/docs/latest/streaming-programming-guide.html#deploying-applications" target="_blank" rel="noopener">部署</a></p>
<h2 id="10-安全"><a href="#10-安全" class="headerlink" title="10 安全"></a>10 安全</h2><p>详见<a href="https://spark.apache.org/docs/latest/structured-streaming-kafka-integration.html#security" target="_blank" rel="noopener">Structured Streaming Security</a></p>
<p>注意：Kafka原生的sink不可用，因此代理令牌只在消费端使用。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://spark.apache.org/docs/latest/streaming-kafka-0-10-integration.html" target="_blank" rel="noopener">Spark Streaming + Kafka Integration Guide (Kafka broker version 0.10.0 or higher)</a></p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Spark/" rel="tag"># Spark</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/08/19/200819高性能索引/" rel="next" title="高性能索引">
                <i class="fa fa-chevron-left"></i> 高性能索引
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2020/09/10/200910Spark Streaming中Kafka的两种接收方式/" rel="prev" title="Spark Streaming中Kafka两种接收方式">
                Spark Streaming中Kafka两种接收方式 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.jpg"
                alt="Hopeful Nick" />
            
              <p class="site-author-name" itemprop="name">Hopeful Nick</p>
              <p class="site-description motion-element" itemprop="description">To Explore</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">161</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                
                  <span class="site-state-item-count">35</span>
                  <span class="site-state-item-name">分类</span>
                
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">42</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/hopefulnick" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:lh848764@gmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-连接"><span class="nav-number">1.</span> <span class="nav-text">1 连接</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-创建直接流"><span class="nav-number">2.</span> <span class="nav-text">2 创建直接流</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-位置策略"><span class="nav-number">3.</span> <span class="nav-text">3 位置策略</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-消费策略"><span class="nav-number">4.</span> <span class="nav-text">4 消费策略</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-创建RDD"><span class="nav-number">5.</span> <span class="nav-text">5 创建RDD</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-获取偏移"><span class="nav-number">6.</span> <span class="nav-text">6 获取偏移</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-保存偏移"><span class="nav-number">7.</span> <span class="nav-text">7 保存偏移</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-检查点"><span class="nav-number">7.1.</span> <span class="nav-text">(1) 检查点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-Kafka"><span class="nav-number">7.2.</span> <span class="nav-text">(2) Kafka</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-自定义"><span class="nav-number">7.3.</span> <span class="nav-text">(3) 自定义</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#8-SSL-TLS"><span class="nav-number">8.</span> <span class="nav-text">8 SSL/TLS</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#9-部署"><span class="nav-number">9.</span> <span class="nav-text">9 部署</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#10-安全"><span class="nav-number">10.</span> <span class="nav-text">10 安全</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参考资料"><span class="nav-number">11.</span> <span class="nav-text">参考资料</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Hopeful Nick</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  

    
      <script id="dsq-count-scr" src="https://hopefulnick.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'https://hopefulnick.github.io/2020/08/29/200829Spark Streaming + Kafka/';
          this.page.identifier = '2020/08/29/200829Spark Streaming + Kafka/';
          this.page.title = 'Spark Streaming + Kafka';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://hopefulnick.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  














  





  

  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  

  

  

  

</body>
</html>
