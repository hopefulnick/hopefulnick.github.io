<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon32.jpg?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon16.jpg?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hudi," />










<meta name="description" content="适用于版本0.10.1。 1 Spark Datasource Writer">
<meta name="keywords" content="Hudi">
<meta property="og:type" content="article">
<meta property="og:title" content="Hudi数据写入">
<meta property="og:url" content="https://hopefulnick.github.io/2022/03/09/20220321Hudi数据写入/index.html">
<meta property="og:site_name" content="Hopeful Nick">
<meta property="og:description" content="适用于版本0.10.1。 1 Spark Datasource Writer">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2022-06-06T08:05:14.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hudi数据写入">
<meta name="twitter:description" content="适用于版本0.10.1。 1 Spark Datasource Writer">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://hopefulnick.github.io/2022/03/09/20220321Hudi数据写入/"/>





  <title>Hudi数据写入 | Hopeful Nick</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hopeful Nick</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://hopefulnick.github.io/2022/03/09/20220321Hudi数据写入/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Hopeful Nick">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hopeful Nick">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Hudi数据写入</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2022-03-09T11:00:47+08:00">
                2022-03-09
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Hudi/" itemprop="url" rel="index">
                    <span itemprop="name">Hudi</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2022/03/09/20220321Hudi数据写入/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2022/03/09/20220321Hudi数据写入/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>适用于版本0.10.1。</p>
<h2 id="1-Spark-Datasource-Writer"><a href="#1-Spark-Datasource-Writer" class="headerlink" title="1 Spark Datasource Writer"></a>1 Spark Datasource Writer</h2><a id="more"></a>
<ul>
<li><p>HoodieWriteConfig</p>
</li>
<li><p>TABLE_NAME：必须</p>
</li>
<li><p>DataSourceWriteOptions</p>
<ul>
<li><p>RECORDKEY_FIELD_OPT_KEY</p>
<p>必须，在分区内唯一指定记录。可通过全局索引设置为全局唯一。默认值：uuid</p>
</li>
<li><p>PARTITIONPATH_FIELD_OPT_KEY</p>
<p>必须，指定分区列。空字符串取消分区。URL_ENCODE_PARTITIONING_OPT_KEY指定URL编码，HIVE_PARTITION_EXTRACTOR_CLASS_OPT_KEY同步Hive。默认：partitionpath</p>
</li>
<li><p>PRECOMBINE_FIELD_OPT_KEY</p>
<p>必须，当同一批数据中出现相同键值，选取指定列中最大的数据插入。设置OverwriteWithLatestAvroPayload后将不采取该策略。默认值：ts</p>
</li>
<li><p>OPERATION_OPT_KEY</p>
<p>写操作使用，默认UPSERT_OPERATION_OPT_VAL , 可选BULK_INSERT_OPERATION_OPT_VAL, INSERT_OPERATION_OPT_VAL, DELETE_OPERATION_OPT_VAL</p>
</li>
<li><p>TABLE_TYPE_OPT_KEY</p>
<p>写入的表类型，需要与建表语句保持一致，并且在Spark中使用SaveMode.Append()模式。默认<a href="https://hudi.apache.org/cn/docs/concepts#copy-on-write-table" target="_blank" rel="noopener"><code>COW_TABLE_TYPE_OPT_VAL</code></a>, 可选<a href="https://hudi.apache.org/cn/docs/concepts#merge-on-read-table" target="_blank" rel="noopener"><code>MOR_TABLE_TYPE_OPT_VAL</code></a></p>
</li>
<li><p>KEYGENERATOR_CLASS_OPT_KEY</p>
<p>详见<a href="https://hudi.apache.org/cn/docs/writing_data#key-generation" target="_blank" rel="noopener">Key Generation</a></p>
</li>
<li><p>HIVE_PARTITION_EXTRACTOR_CLASS_OPT_KEY</p>
<p>使用hive时，指定表是否分区。</p>
<p>默认classOf[SlashEncodedDayPartitionValueExtractor].getCanonicalName,</p>
<p>可选classOf[MultiPartKeysValueExtractor].getCanonicalName, classOf[TimestampBasedKeyGenerator].getCanonicalName, </p>
<p>classOf[NonPartitionedExtractor].getCanonicalName, </p>
<p>classOf[GlobalDeleteKeyGenerator].getCanonicalName (OPERATION_OPT_KEY为DELETE_OPERATION_OPT_VAL时)</p>
</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">inputDF.write()</span><br><span class="line">       .format(<span class="string">"org.apache.hudi"</span>)</span><br><span class="line">       .options(clientOpts) <span class="comment">//Where clientOpts is of type Map[String, String]. clientOpts can include any other options necessary.</span></span><br><span class="line">       .option(<span class="type">DataSourceWriteOptions</span>.<span class="type">RECORDKEY_FIELD_OPT_KEY</span>(), <span class="string">"_row_key"</span>)</span><br><span class="line">       .option(<span class="type">DataSourceWriteOptions</span>.<span class="type">PARTITIONPATH_FIELD_OPT_KEY</span>(), <span class="string">"partition"</span>)</span><br><span class="line">       .option(<span class="type">DataSourceWriteOptions</span>.<span class="type">PRECOMBINE_FIELD_OPT_KEY</span>(), <span class="string">"timestamp"</span>)</span><br><span class="line">       .option(<span class="type">HoodieWriteConfig</span>.<span class="type">TABLE_NAME</span>, tableName)</span><br><span class="line">       .mode(<span class="type">SaveMode</span>.<span class="type">Append</span>)</span><br><span class="line">       .save(basePath);</span><br></pre></td></tr></table></figure>
<p>Spark SQL示例：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> h0 <span class="keyword">select</span> <span class="number">1</span>, <span class="string">'a1'</span>, <span class="number">20</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- insert static partition</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> h_p0 <span class="keyword">partition</span>(dt = <span class="string">'2021-01-02'</span>) <span class="keyword">select</span> <span class="number">1</span>, <span class="string">'a1'</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- insert dynamic partition</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> h_p0 <span class="keyword">select</span> <span class="number">1</span>, <span class="string">'a1'</span>, dt;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- insert dynamic partition</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> h_p1 <span class="keyword">select</span> <span class="number">1</span> <span class="keyword">as</span> <span class="keyword">id</span>, <span class="string">'a1'</span>, <span class="string">'2021-01-03'</span> <span class="keyword">as</span> dt, <span class="string">'19'</span> <span class="keyword">as</span> hh;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- insert overwrite table</span></span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> h0 <span class="keyword">select</span> <span class="number">1</span>, <span class="string">'a1'</span>, <span class="number">20</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- insert overwrite table with static partition</span></span><br><span class="line"><span class="keyword">insert</span> overwrite h_p0 <span class="keyword">partition</span>(dt = <span class="string">'2021-01-02'</span>) <span class="keyword">select</span> <span class="number">1</span>, <span class="string">'a1'</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- insert overwrite table with dynamic partition</span></span><br><span class="line">  <span class="keyword">insert</span> overwrite <span class="keyword">table</span> h_p1 <span class="keyword">select</span> <span class="number">2</span> <span class="keyword">as</span> <span class="keyword">id</span>, <span class="string">'a2'</span>, <span class="string">'2021-01-03'</span> <span class="keyword">as</span> dt, <span class="string">'19'</span> <span class="keyword">as</span> hh;</span><br></pre></td></tr></table></figure>
<p>注意：</p>
<ul>
<li><p>Insert</p>
<ul>
<li>strict模式：插入重复键名时，cow表抛异常，mor表更新数据。</li>
<li>非strict模式：同Spark DataSourceah中insert操作，可以设置hoodie.sql.insert.mode变更。</li>
</ul>
</li>
<li><p>Bulk insert</p>
<p>默认使用insert，可以设置hoodie.sql.bulk.insert.enable开启。</p>
</li>
</ul>
</li>
</ul>
<h3 id="1-插入覆盖非分区表"><a href="#1-插入覆盖非分区表" class="headerlink" title="(1) 插入覆盖非分区表"></a>(1) 插入覆盖非分区表</h3><p>相比先删后插入，效率更高。Hudi Cleaner最终会清理之前的快照文件组。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> h0 <span class="keyword">select</span> <span class="number">1</span>, <span class="string">'a1'</span>, <span class="number">20</span>;</span><br></pre></td></tr></table></figure>
<h3 id="2-插入覆盖分区表"><a href="#2-插入覆盖分区表" class="headerlink" title="(2) 插入覆盖分区表"></a>(2) 插入覆盖分区表</h3><p>因充分利用了索引、预聚合和再分区操作，相比upsert更加高效。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> h_p1 <span class="keyword">select</span> <span class="number">2</span> <span class="keyword">as</span> <span class="keyword">id</span>, <span class="string">'a2'</span>, <span class="string">'2021-01-03'</span> <span class="keyword">as</span> dt, <span class="string">'19'</span> <span class="keyword">as</span> hh;</span><br></pre></td></tr></table></figure>
<h3 id="3-删除"><a href="#3-删除" class="headerlink" title="(3) 删除"></a>(3) 删除</h3><p>Hudi支持两种删除模式，详见<a href="https://cwiki.apache.org/confluence/x/6IqvC" target="_blank" rel="noopener">Delete support in Hudi</a>。</p>
<ul>
<li><p>软删除</p>
<p>保留记录键，将其他字段置为null</p>
</li>
<li><p>硬删除</p>
<p>物理删除。</p>
<p>通过以下三种方式设置：</p>
<ul>
<li><p>使用Datasource时，设置OPERATION_OPT_KEY为DELETE_OPERATION_OPT_VAL。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> deletes = dataGen.generateDeletes(df.collectAsList())</span><br><span class="line"><span class="keyword">val</span> df = spark.read.json(spark.sparkContext.parallelize(deletes, <span class="number">2</span>));</span><br><span class="line">df.write.format(<span class="string">"org.apache.hudi"</span>).</span><br><span class="line">options(getQuickstartWriteConfigs).</span><br><span class="line"><span class="comment">// DELETE_OPERATION_OPT_VAL?</span></span><br><span class="line">option(<span class="type">OPERATION_OPT_KEY</span>,<span class="string">"delete"</span>).</span><br><span class="line">option(<span class="type">PRECOMBINE_FIELD_OPT_KEY</span>, <span class="string">"ts"</span>).</span><br><span class="line">option(<span class="type">RECORDKEY_FIELD_OPT_KEY</span>, <span class="string">"uuid"</span>).</span><br><span class="line">option(<span class="type">PARTITIONPATH_FIELD_OPT_KEY</span>, <span class="string">"partitionpath"</span>).</span><br><span class="line">option(<span class="type">TABLE_NAME</span>, tableName).</span><br><span class="line">mode(<span class="type">Append</span>).</span><br><span class="line">save(basePath);</span><br></pre></td></tr></table></figure>
</li>
<li><p>使用DataSource时，设置PAYLOAD_CLASS_OPT_KEY为”org.apache.hudi.EmptyHoodieRecordPayload”。将删除提交的所有记录。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">deleteDF <span class="comment">// dataframe containing just records to be deleted</span></span><br><span class="line">  .write().format(<span class="string">"org.apache.hudi"</span>)</span><br><span class="line">  .option(...) <span class="comment">// Add HUDI options like record-key, partition-path and others as needed for your setup</span></span><br><span class="line">  <span class="comment">// specify record_key, partition_key, precombine_fieldkey &amp; usual params</span></span><br><span class="line">  .option(<span class="type">DataSourceWriteOptions</span>.<span class="type">PAYLOAD_CLASS_OPT_KEY</span>, <span class="string">"org.apache.hudi.EmptyHoodieRecordPayload"</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>使用DataSource或DeltaStreamer，为需要删除的记录添加列_hoodie_is_deleted，并设置为true。</p>
</li>
</ul>
</li>
</ul>
<h3 id="4-并发控制"><a href="#4-并发控制" class="headerlink" title="(4) 并发控制"></a>(4) 并发控制</h3><p>hudi-spark模块提供了DataSource API来读写Spark DataFrame到hudi表中。详见<a href="https://hudi.apache.org/docs/concurrency_control" target="_blank" rel="noopener">concurrency control concepts</a>。</p>
<p>示例如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">inputDF.write.format(<span class="string">"hudi"</span>)</span><br><span class="line">       .options(getQuickstartWriteConfigs)</span><br><span class="line">       .option(<span class="type">PRECOMBINE_FIELD_OPT_KEY</span>, <span class="string">"ts"</span>)</span><br><span class="line">       .option(<span class="string">"hoodie.cleaner.policy.failed.writes"</span>, <span class="string">"LAZY"</span>)</span><br><span class="line">       .option(<span class="string">"hoodie.write.concurrency.mode"</span>, <span class="string">"optimistic_concurrency_control"</span>)</span><br><span class="line">       .option(<span class="string">"hoodie.write.lock.zookeeper.url"</span>, <span class="string">"zookeeper"</span>)</span><br><span class="line">       .option(<span class="string">"hoodie.write.lock.zookeeper.port"</span>, <span class="string">"2181"</span>)</span><br><span class="line">       .option(<span class="string">"hoodie.write.lock.zookeeper.lock_key"</span>, <span class="string">"test_table"</span>)</span><br><span class="line">       .option(<span class="string">"hoodie.write.lock.zookeeper.base_path"</span>, <span class="string">"/test"</span>)</span><br><span class="line">       .option(<span class="type">RECORDKEY_FIELD_OPT_KEY</span>, <span class="string">"uuid"</span>)</span><br><span class="line">       .option(<span class="type">PARTITIONPATH_FIELD_OPT_KEY</span>, <span class="string">"partitionpath"</span>)</span><br><span class="line">       .option(<span class="type">TABLE_NAME</span>, tableName)</span><br><span class="line">       .mode(<span class="type">Overwrite</span>)</span><br><span class="line">       .save(basePath)</span><br></pre></td></tr></table></figure>
<h3 id="5-提交通知"><a href="#5-提交通知" class="headerlink" title="(5) 提交通知"></a>(5) 提交通知</h3><p>提供关于写提交的回调通知。</p>
<ul>
<li><p>HTTP</p>
<p>| Config                           | Description                                                  | Required | Default                                                     |<br>| ——————————– | ———————————————————— | ——– | ———————————————————– |<br>| TURN_CALLBACK_ON                 | Turn commit callback on/off                                  | optional | false (<em>callbacks off</em>)                                     |<br>| CALLBACK_HTTP_URL                | Callback host to be sent along with callback messages        | required | N/A                                                         |<br>| CALLBACK_HTTP_TIMEOUT_IN_SECONDS | Callback timeout in seconds                                  | optional | 3                                                           |<br>| CALLBACK_CLASS_NAME              | Full path of callback class and must be a subclass of HoodieWriteCommitCallback class, org.apache.hudi.callback.impl.HoodieWriteCommitHttpCallback by default | optional | org.apache.hudi.callback.impl.HoodieWriteCommitHttpCallback |<br>| CALLBACK_HTTP_API_KEY_VALUE      | Http callback API key                                        | optional | hudi_write_commit_http_callback                             |<br>|                                  |                                                              |          |                                                             |</p>
</li>
<li><p>Kafka</p>
<p>| Config            | Description                                                  | Required | Default |<br>| —————– | ———————————————————— | ——– | ——- |<br>| TOPIC             | Kafka topic name to publish timeline activity into.          | required | N/A     |<br>| PARTITION         | It may be desirable to serialize all changes into a single Kafka partition for providing strict ordering. By default, Kafka messages are keyed by table name, which guarantees ordering at the table level, but not globally (or when new partitions are added) | required | N/A     |<br>| RETRIES           | Times to retry the produce                                   | optional | 3       |<br>| ACKS              | kafka acks level, all by default to ensure strong durability | optional | all     |<br>| BOOTSTRAP_SERVERS | Bootstrap servers of kafka cluster, to be used for publishing commit metadata | required | N/A     |</p>
</li>
<li><p>自定义实现</p>
<p>自定义扩展HoodieWriteCommitCallback，实现消息回调。详见<a href="https://github.com/apache/hudi/blob/master/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/callback/HoodieWriteCommitCallback.java" target="_blank" rel="noopener">API</a>。</p>
</li>
</ul>
<h2 id="2-Flink-SQL-Writer"><a href="#2-Flink-SQL-Writer" class="headerlink" title="2 Flink SQL Writer"></a>2 Flink SQL Writer</h2><p>宿表配置</p>
<table>
<thead>
<tr>
<th>Option Name</th>
<th>Required</th>
<th>Default</th>
<th>Remarks</th>
</tr>
</thead>
<tbody>
<tr>
<td>path</td>
<td>Y</td>
<td>N/A</td>
<td>Base path for the target hoodie table. The path would be created if it does not exist, otherwise a hudi table expects to be initialized successfully</td>
</tr>
<tr>
<td>table.type</td>
<td>N</td>
<td>COPY_ON_WRITE</td>
<td>Type of table to write. COPY_ON_WRITE (or) MERGE_ON_READ</td>
</tr>
<tr>
<td>write.operation</td>
<td>N</td>
<td>upsert</td>
<td>The write operation, that this write should do (insert or upsert is supported)</td>
</tr>
<tr>
<td>write.precombine.field</td>
<td>N</td>
<td>ts</td>
<td>Field used in preCombining before actual write. When two records have the same key value, we will pick the one with the largest value for the precombine field, determined by Object.compareTo(..)</td>
</tr>
<tr>
<td>write.payload.class</td>
<td>N</td>
<td>OverwriteWithLatestAvroPayload.class</td>
<td>Payload class used. Override this, if you like to roll your own merge logic, when upserting/inserting. This will render any value set for the option in-effective</td>
</tr>
<tr>
<td>write.insert.drop.duplicates</td>
<td>N</td>
<td>false</td>
<td>Flag to indicate whether to drop duplicates upon insert. By default insert will accept duplicates, to gain extra performance</td>
</tr>
<tr>
<td>write.ignore.failed</td>
<td>N</td>
<td>true</td>
<td>Flag to indicate whether to ignore any non exception error (e.g. writestatus error). within a checkpoint batch. By default true (in favor of streaming progressing over data integrity)</td>
</tr>
<tr>
<td>hoodie.datasource.write.recordkey.field</td>
<td>N</td>
<td>uuid</td>
<td>Record key field. Value to be used as the <code>recordKey</code> component of <code>HoodieKey</code>. Actual value will be obtained by invoking .toString() on the field value. Nested fields can be specified using the dot notation eg: <code>a.b.c</code></td>
</tr>
<tr>
<td>hoodie.datasource.write.keygenerator.class</td>
<td>N</td>
<td>SimpleAvroKeyGenerator.class</td>
<td>Key generator class, that implements will extract the key out of incoming record</td>
</tr>
<tr>
<td>write.tasks</td>
<td>N</td>
<td>4</td>
<td>Parallelism of tasks that do actual write, default is 4</td>
</tr>
<tr>
<td>write.batch.size.MB</td>
<td>N</td>
<td>128</td>
<td>Batch buffer size in MB to flush data into the underneath filesystem</td>
</tr>
</tbody>
</table>
<p>MOR表异步压缩策略</p>
<table>
<thead>
<tr>
<th>Option Name</th>
<th>Required</th>
<th>Default</th>
<th>Remarks</th>
</tr>
</thead>
<tbody>
<tr>
<td>compaction.async.enabled</td>
<td>N</td>
<td>true</td>
<td>Async Compaction, enabled by default for MOR</td>
</tr>
<tr>
<td>compaction.trigger.strategy</td>
<td>N</td>
<td>num_commits</td>
<td>Strategy to trigger compaction, options are ‘num_commits’: trigger compaction when reach N delta commits; ‘time_elapsed’: trigger compaction when time elapsed &gt; N seconds since last compaction; ‘num_and_time’: trigger compaction when both NUM_COMMITS and TIME_ELAPSED are satisfied; ‘num_or_time’: trigger compaction when NUM_COMMITS or TIME_ELAPSED is satisfied. Default is ‘num_commits’</td>
</tr>
<tr>
<td>compaction.delta_commits</td>
<td>N</td>
<td>5</td>
<td>Max delta commits needed to trigger compaction, default 5 commits</td>
</tr>
<tr>
<td>compaction.delta_seconds</td>
<td>N</td>
<td>3600</td>
<td>Max delta seconds time needed to trigger compaction, default 1 hour</td>
</tr>
</tbody>
</table>
<p>当前仅支持Insert into。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2>
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Hudi/" rel="tag"># Hudi</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2022/03/09/20220309Hudi键更新/" rel="next" title="Hudi键更新">
                <i class="fa fa-chevron-left"></i> Hudi键更新
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2022/03/09/20220309Hudi模式修改/" rel="prev" title="Hudi模式修改">
                Hudi模式修改 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.jpg"
                alt="Hopeful Nick" />
            
              <p class="site-author-name" itemprop="name">Hopeful Nick</p>
              <p class="site-description motion-element" itemprop="description">To Explore</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">161</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                
                  <span class="site-state-item-count">35</span>
                  <span class="site-state-item-name">分类</span>
                
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">42</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/hopefulnick" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:lh848764@gmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-Spark-Datasource-Writer"><span class="nav-number">1.</span> <span class="nav-text">1 Spark Datasource Writer</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-插入覆盖非分区表"><span class="nav-number">1.1.</span> <span class="nav-text">(1) 插入覆盖非分区表</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-插入覆盖分区表"><span class="nav-number">1.2.</span> <span class="nav-text">(2) 插入覆盖分区表</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-删除"><span class="nav-number">1.3.</span> <span class="nav-text">(3) 删除</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-并发控制"><span class="nav-number">1.4.</span> <span class="nav-text">(4) 并发控制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-提交通知"><span class="nav-number">1.5.</span> <span class="nav-text">(5) 提交通知</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-Flink-SQL-Writer"><span class="nav-number">2.</span> <span class="nav-text">2 Flink SQL Writer</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参考资料"><span class="nav-number">3.</span> <span class="nav-text">参考资料</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Hopeful Nick</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  

    
      <script id="dsq-count-scr" src="https://hopefulnick.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'https://hopefulnick.github.io/2022/03/09/20220321Hudi数据写入/';
          this.page.identifier = '2022/03/09/20220321Hudi数据写入/';
          this.page.title = 'Hudi数据写入';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://hopefulnick.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  














  





  

  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  

  

  

  

</body>
</html>
